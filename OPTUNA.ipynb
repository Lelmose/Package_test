{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optuna: hyper-parameters optimization\n",
    "\n",
    "Code and tutos taken from: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Bastien\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\requests\\__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.7) or chardet (5.1.0)/charset_normalizer (2.0.6) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import optuna\n",
    "from optuna.trial import TrialState\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 15:39:03,340]\u001b[0m A new study created in memory with name: no-name-5fd9e933-2e4b-4690-9b0d-e0315be48b7b\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,347]\u001b[0m Trial 0 finished with value: 18.893653106180896 and parameters: {'x': 6.3466830004246795}. Best is trial 0 with value: 18.893653106180896.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,348]\u001b[0m Trial 1 finished with value: 19.378618809957132 and parameters: {'x': 6.402115265410156}. Best is trial 0 with value: 18.893653106180896.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,348]\u001b[0m Trial 2 finished with value: 11.243607299231527 and parameters: {'x': 5.3531488632674105}. Best is trial 2 with value: 11.243607299231527.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,349]\u001b[0m Trial 3 finished with value: 21.71044625420755 and parameters: {'x': 6.659446990170352}. Best is trial 2 with value: 11.243607299231527.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,350]\u001b[0m Trial 4 finished with value: 3.0652381330285374 and parameters: {'x': 0.2492178510652625}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,350]\u001b[0m Trial 5 finished with value: 42.378585537411986 and parameters: {'x': -4.509883680789695}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,351]\u001b[0m Trial 6 finished with value: 65.868393025444 and parameters: {'x': -6.115934513378236}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,352]\u001b[0m Trial 7 finished with value: 25.93079981621961 and parameters: {'x': 7.092229356207319}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,353]\u001b[0m Trial 8 finished with value: 94.04897560468976 and parameters: {'x': -7.697885109893279}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,354]\u001b[0m Trial 9 finished with value: 104.3044956135231 and parameters: {'x': -8.21295724134411}. Best is trial 4 with value: 3.0652381330285374.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,374]\u001b[0m Trial 10 finished with value: 2.5729828314732672 and parameters: {'x': 0.3959479960196842}. Best is trial 10 with value: 2.5729828314732672.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,380]\u001b[0m Trial 11 finished with value: 2.715858802694411 and parameters: {'x': 0.3520137128318056}. Best is trial 10 with value: 2.5729828314732672.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,384]\u001b[0m Trial 12 finished with value: 2.427120077116156 and parameters: {'x': 0.44207828273813576}. Best is trial 12 with value: 2.427120077116156.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,390]\u001b[0m Trial 13 finished with value: 22.670602973552477 and parameters: {'x': -2.7613656626594514}. Best is trial 12 with value: 2.427120077116156.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,396]\u001b[0m Trial 14 finished with value: 0.3040136730990511 and parameters: {'x': 1.448625650670027}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,402]\u001b[0m Trial 15 finished with value: 1.871136856597326 and parameters: {'x': 3.3678950458998402}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,407]\u001b[0m Trial 16 finished with value: 2.217476076802532 and parameters: {'x': 3.48911922853831}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,414]\u001b[0m Trial 17 finished with value: 63.96517978221189 and parameters: {'x': 9.997823440299985}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,418]\u001b[0m Trial 18 finished with value: 1.9171551504000435 and parameters: {'x': 3.3846137188400394}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,424]\u001b[0m Trial 19 finished with value: 13.197056103512693 and parameters: {'x': -1.6327752619055165}. Best is trial 14 with value: 0.3040136730990511.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,433]\u001b[0m Trial 20 finished with value: 8.029316770731016e-05 and parameters: {'x': 1.9910393545038703}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,438]\u001b[0m Trial 21 finished with value: 0.07325997149102503 and parameters: {'x': 2.2706657929828316}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,445]\u001b[0m Trial 22 finished with value: 0.2511978426334893 and parameters: {'x': 1.4988035887663507}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,452]\u001b[0m Trial 23 finished with value: 0.005116142303357508 and parameters: {'x': 1.9284727862743312}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,457]\u001b[0m Trial 24 finished with value: 14.291151943594768 and parameters: {'x': -1.7803639961774538}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,465]\u001b[0m Trial 25 finished with value: 0.3097855535422402 and parameters: {'x': 2.556583824362728}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,487]\u001b[0m Trial 26 finished with value: 12.170136470790727 and parameters: {'x': -1.4885722682482483}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,497]\u001b[0m Trial 27 finished with value: 5.078094417797505 and parameters: {'x': 4.253462761573287}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,507]\u001b[0m Trial 28 finished with value: 0.009943835074508543 and parameters: {'x': 1.9002812200510428}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,514]\u001b[0m Trial 29 finished with value: 8.845712750415252 and parameters: {'x': 4.974174297248776}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,521]\u001b[0m Trial 30 finished with value: 0.0001988302746752204 and parameters: {'x': 1.9858992810582148}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,531]\u001b[0m Trial 31 finished with value: 0.1899615200467978 and parameters: {'x': 1.5641542474145265}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,539]\u001b[0m Trial 32 finished with value: 8.295808752130005 and parameters: {'x': -0.8802445646385664}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,545]\u001b[0m Trial 33 finished with value: 0.12872355337130612 and parameters: {'x': 2.35878064798886}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,549]\u001b[0m Trial 34 finished with value: 6.371749969416053 and parameters: {'x': -0.5242325505816718}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,557]\u001b[0m Trial 35 finished with value: 9.76148189309863 and parameters: {'x': 5.124337032571651}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,562]\u001b[0m Trial 36 finished with value: 0.32818547757175814 and parameters: {'x': 1.4271252514102597}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,569]\u001b[0m Trial 37 finished with value: 141.96001391283482 and parameters: {'x': -9.91469739073699}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,578]\u001b[0m Trial 38 finished with value: 15.391338129915946 and parameters: {'x': 5.923179594399923}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,584]\u001b[0m Trial 39 finished with value: 22.154541044256444 and parameters: {'x': -2.7068610606492776}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,589]\u001b[0m Trial 40 finished with value: 4.519894561622075 and parameters: {'x': 4.126004365381707}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,593]\u001b[0m Trial 41 finished with value: 0.228609509748585 and parameters: {'x': 2.4781312683234438}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,600]\u001b[0m Trial 42 finished with value: 1.924616852237087 and parameters: {'x': 0.6126943911894946}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,611]\u001b[0m Trial 43 finished with value: 0.2585247038946716 and parameters: {'x': 2.508453246517978}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,616]\u001b[0m Trial 44 finished with value: 4.762062958034552 and parameters: {'x': -0.18221514934585503}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,623]\u001b[0m Trial 45 finished with value: 1.7162952632583082 and parameters: {'x': 0.6899254741586995}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,629]\u001b[0m Trial 46 finished with value: 0.049155786970819286 and parameters: {'x': 2.221711043862996}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,634]\u001b[0m Trial 47 finished with value: 0.4751629178058097 and parameters: {'x': 1.3106793795295184}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,640]\u001b[0m Trial 48 finished with value: 4.965141806649487 and parameters: {'x': -0.22825981578663468}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,651]\u001b[0m Trial 49 finished with value: 1.2202778200372497 and parameters: {'x': 3.1046618577814886}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,659]\u001b[0m Trial 50 finished with value: 4.866835504117304 and parameters: {'x': 4.206090547578976}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,666]\u001b[0m Trial 51 finished with value: 0.0012954775172565338 and parameters: {'x': 2.0359927425636966}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,672]\u001b[0m Trial 52 finished with value: 0.0050414265606914055 and parameters: {'x': 1.9289969961150135}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,677]\u001b[0m Trial 53 finished with value: 1.5359926419438699 and parameters: {'x': 0.7606482977201872}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,684]\u001b[0m Trial 54 finished with value: 1.3401465000121153 and parameters: {'x': 3.1576469669169938}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,689]\u001b[0m Trial 55 finished with value: 0.011112350222165699 and parameters: {'x': 1.8945848672051033}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,697]\u001b[0m Trial 56 finished with value: 0.2991268476611024 and parameters: {'x': 1.453075098700834}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,704]\u001b[0m Trial 57 finished with value: 2.4180466205346485 and parameters: {'x': 0.4449930480751385}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,711]\u001b[0m Trial 58 finished with value: 1.0976747136645233 and parameters: {'x': 3.047699724952013}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,718]\u001b[0m Trial 59 finished with value: 1.2168101799448245 and parameters: {'x': 0.8969088070586256}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,724]\u001b[0m Trial 60 finished with value: 0.0019391691602063637 and parameters: {'x': 1.955964001541848}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,731]\u001b[0m Trial 61 finished with value: 0.012780757854093858 and parameters: {'x': 1.8869479860679437}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,735]\u001b[0m Trial 62 finished with value: 2.4217835266527916 and parameters: {'x': 3.556208060206858}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,742]\u001b[0m Trial 63 finished with value: 3.869294926264057 and parameters: {'x': 0.032947655433628986}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,748]\u001b[0m Trial 64 finished with value: 0.9901851099033433 and parameters: {'x': 1.0049195460148244}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,754]\u001b[0m Trial 65 finished with value: 0.02650141416748704 and parameters: {'x': 2.1627925494839584}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,762]\u001b[0m Trial 66 finished with value: 3.221855679186224 and parameters: {'x': 3.794952834808264}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,771]\u001b[0m Trial 67 finished with value: 1.223759000325285 and parameters: {'x': 3.106236412492956}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,776]\u001b[0m Trial 68 finished with value: 0.4418657542036389 and parameters: {'x': 2.664729835499836}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,786]\u001b[0m Trial 69 finished with value: 7.537942930776213 and parameters: {'x': 4.745531447784966}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,796]\u001b[0m Trial 70 finished with value: 0.04747660753756481 and parameters: {'x': 1.7821087254212211}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,803]\u001b[0m Trial 71 finished with value: 0.013227991944492638 and parameters: {'x': 1.8849869922813396}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,812]\u001b[0m Trial 72 finished with value: 0.8415017375209005 and parameters: {'x': 1.08266596186509}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,816]\u001b[0m Trial 73 finished with value: 0.6534345718399243 and parameters: {'x': 2.8083529995242946}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,822]\u001b[0m Trial 74 finished with value: 0.05563811006629299 and parameters: {'x': 1.7641226800510634}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,828]\u001b[0m Trial 75 finished with value: 3.3273260649298018 and parameters: {'x': 0.17590404174292362}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,834]\u001b[0m Trial 76 finished with value: 2.840442523313313 and parameters: {'x': 3.6853612441590418}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,842]\u001b[0m Trial 77 finished with value: 7.087954860271405 and parameters: {'x': -0.6623213292672627}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,848]\u001b[0m Trial 78 finished with value: 0.021333411817872718 and parameters: {'x': 2.146059617341251}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,853]\u001b[0m Trial 79 finished with value: 0.746741216208763 and parameters: {'x': 1.1358581041236555}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,861]\u001b[0m Trial 80 finished with value: 0.3254446389155041 and parameters: {'x': 2.5704775533844466}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,866]\u001b[0m Trial 81 finished with value: 0.01508269403703957 and parameters: {'x': 1.8771883798778}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,872]\u001b[0m Trial 82 finished with value: 0.3774794965549044 and parameters: {'x': 1.3856063993213272}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,880]\u001b[0m Trial 83 finished with value: 0.007131488404307637 and parameters: {'x': 2.084448140324744}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,884]\u001b[0m Trial 84 finished with value: 0.5963867779126039 and parameters: {'x': 2.77226082246389}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,891]\u001b[0m Trial 85 finished with value: 2.147480506791353 and parameters: {'x': 0.5345715620367697}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,899]\u001b[0m Trial 86 finished with value: 0.04929537570614611 and parameters: {'x': 2.222025619481505}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,904]\u001b[0m Trial 87 finished with value: 2.2443122894884944 and parameters: {'x': 3.4981028968293515}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,909]\u001b[0m Trial 88 finished with value: 0.45604221881780327 and parameters: {'x': 1.3246910197414792}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,916]\u001b[0m Trial 89 finished with value: 6.378794820912732 and parameters: {'x': 4.5256276093107495}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,923]\u001b[0m Trial 90 finished with value: 4.622656806163802 and parameters: {'x': 4.1500364662404685}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,955]\u001b[0m Trial 91 finished with value: 0.07607565457330359 and parameters: {'x': 1.7241818450984352}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,967]\u001b[0m Trial 92 finished with value: 0.7316183714392268 and parameters: {'x': 2.855346930455255}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,973]\u001b[0m Trial 93 finished with value: 0.08066931050752979 and parameters: {'x': 2.284023433025393}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,985]\u001b[0m Trial 94 finished with value: 1.1371765312435997 and parameters: {'x': 0.9336152048891547}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:03,993]\u001b[0m Trial 95 finished with value: 3.142271683785066 and parameters: {'x': 0.22735460856237077}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:04,000]\u001b[0m Trial 96 finished with value: 0.01563442417402671 and parameters: {'x': 1.8749623089863432}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:04,006]\u001b[0m Trial 97 finished with value: 0.9681576679556484 and parameters: {'x': 2.9839500332616735}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:04,014]\u001b[0m Trial 98 finished with value: 1.7891859243183066 and parameters: {'x': 3.3376045470610163}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:39:04,019]\u001b[0m Trial 99 finished with value: 1.6400647085314406 and parameters: {'x': 0.719349888325683}. Best is trial 20 with value: 8.029316770731016e-05.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'x': 1.9910393545038703}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    x = trial.suggest_float('x', -10, 10)\n",
    "    return (x - 2) ** 2\n",
    "\n",
    "study = optuna.create_study()\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "study.best_params  # E.g. {'x': 2.002108042}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optuna for PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 15:49:50,229]\u001b[0m A new study created in memory with name: no-name-7f511aed-e995-412b-aec3-5e5df9381798\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:05<00:00, 5213263.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\train-images-idx3-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 2635335.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\train-labels-idx1-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 4092925.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\t10k-images-idx3-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 5147145.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\\t10k-labels-idx1-ubyte.gz to c:\\Users\\Bastien\\Documents\\GitHub\\Package_test\\FashionMNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-05-16 15:50:05,267]\u001b[0m Trial 0 finished with value: 0.703125 and parameters: {'n_layers': 2, 'n_units_l0': 83, 'dropout_l0': 0.21184075634012306, 'n_units_l1': 13, 'dropout_l1': 0.42734728789034504, 'optimizer': 'Adam', 'lr': 0.02477645026468584}. Best is trial 0 with value: 0.703125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:11,786]\u001b[0m Trial 1 finished with value: 0.74453125 and parameters: {'n_layers': 1, 'n_units_l0': 52, 'dropout_l0': 0.36209938991456725, 'optimizer': 'RMSprop', 'lr': 0.0002070729127908854}. Best is trial 1 with value: 0.74453125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:22,071]\u001b[0m Trial 2 finished with value: 0.290625 and parameters: {'n_layers': 2, 'n_units_l0': 20, 'dropout_l0': 0.42470852492108613, 'n_units_l1': 99, 'dropout_l1': 0.22937070167680376, 'optimizer': 'RMSprop', 'lr': 0.02578205074605253}. Best is trial 1 with value: 0.74453125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:29,024]\u001b[0m Trial 3 finished with value: 0.07109375 and parameters: {'n_layers': 1, 'n_units_l0': 111, 'dropout_l0': 0.3050816676952799, 'optimizer': 'SGD', 'lr': 1.2590513456065612e-05}. Best is trial 1 with value: 0.74453125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:35,949]\u001b[0m Trial 4 finished with value: 0.6421875 and parameters: {'n_layers': 2, 'n_units_l0': 67, 'dropout_l0': 0.319849282782712, 'n_units_l1': 103, 'dropout_l1': 0.3650788578143793, 'optimizer': 'Adam', 'lr': 8.847242066235975e-05}. Best is trial 1 with value: 0.74453125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:36,706]\u001b[0m Trial 5 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:37,436]\u001b[0m Trial 6 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:38,203]\u001b[0m Trial 7 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:38,920]\u001b[0m Trial 8 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:39,669]\u001b[0m Trial 9 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:46,305]\u001b[0m Trial 10 finished with value: 0.80234375 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'dropout_l0': 0.26836004620547094, 'optimizer': 'RMSprop', 'lr': 0.002589019131024688}. Best is trial 10 with value: 0.80234375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:53,039]\u001b[0m Trial 11 finished with value: 0.79921875 and parameters: {'n_layers': 1, 'n_units_l0': 46, 'dropout_l0': 0.272074348159996, 'optimizer': 'RMSprop', 'lr': 0.0023673402738471406}. Best is trial 10 with value: 0.80234375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:50:59,568]\u001b[0m Trial 12 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 42, 'dropout_l0': 0.2618603443556651, 'optimizer': 'RMSprop', 'lr': 0.002532406939753458}. Best is trial 12 with value: 0.81484375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:06,284]\u001b[0m Trial 13 finished with value: 0.81328125 and parameters: {'n_layers': 1, 'n_units_l0': 36, 'dropout_l0': 0.24339132086552165, 'optimizer': 'RMSprop', 'lr': 0.0018520903605843675}. Best is trial 12 with value: 0.81484375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:06,994]\u001b[0m Trial 14 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:13,854]\u001b[0m Trial 15 finished with value: 0.80625 and parameters: {'n_layers': 1, 'n_units_l0': 77, 'dropout_l0': 0.24625141596642944, 'optimizer': 'RMSprop', 'lr': 0.0013849563283486962}. Best is trial 12 with value: 0.81484375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:20,479]\u001b[0m Trial 16 finished with value: 0.78671875 and parameters: {'n_layers': 1, 'n_units_l0': 32, 'dropout_l0': 0.24229102814457132, 'optimizer': 'RMSprop', 'lr': 0.004812324327059915}. Best is trial 12 with value: 0.81484375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:21,247]\u001b[0m Trial 17 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:22,019]\u001b[0m Trial 18 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:24,732]\u001b[0m Trial 19 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:25,500]\u001b[0m Trial 20 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:32,251]\u001b[0m Trial 21 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.24230361442440407, 'optimizer': 'RMSprop', 'lr': 0.0011014728200507032}. Best is trial 12 with value: 0.81484375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:39,008]\u001b[0m Trial 22 finished with value: 0.83125 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.23573251203161433, 'optimizer': 'RMSprop', 'lr': 0.0010600269200269836}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:45,781]\u001b[0m Trial 23 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 89, 'dropout_l0': 0.2820926237366104, 'optimizer': 'RMSprop', 'lr': 0.0008225717560262855}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:52,526]\u001b[0m Trial 24 finished with value: 0.803125 and parameters: {'n_layers': 1, 'n_units_l0': 73, 'dropout_l0': 0.228030579434988, 'optimizer': 'RMSprop', 'lr': 0.0021372784276326084}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:53,964]\u001b[0m Trial 25 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:51:58,350]\u001b[0m Trial 26 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:05,862]\u001b[0m Trial 27 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 67, 'dropout_l0': 0.28875928727060163, 'optimizer': 'RMSprop', 'lr': 0.003712320535824656}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:07,288]\u001b[0m Trial 28 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:08,528]\u001b[0m Trial 29 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:09,728]\u001b[0m Trial 30 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:10,800]\u001b[0m Trial 31 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:13,184]\u001b[0m Trial 32 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:19,210]\u001b[0m Trial 33 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:28,334]\u001b[0m Trial 34 finished with value: 0.79296875 and parameters: {'n_layers': 1, 'n_units_l0': 70, 'dropout_l0': 0.2137714210902283, 'optimizer': 'RMSprop', 'lr': 0.0035541007532795465}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:29,308]\u001b[0m Trial 35 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:30,440]\u001b[0m Trial 36 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:31,627]\u001b[0m Trial 37 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:32,685]\u001b[0m Trial 38 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:33,653]\u001b[0m Trial 39 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:34,745]\u001b[0m Trial 40 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:35,656]\u001b[0m Trial 41 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:38,636]\u001b[0m Trial 42 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:39,573]\u001b[0m Trial 43 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:40,674]\u001b[0m Trial 44 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:41,722]\u001b[0m Trial 45 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:42,761]\u001b[0m Trial 46 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:43,673]\u001b[0m Trial 47 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:44,783]\u001b[0m Trial 48 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:52:54,528]\u001b[0m Trial 49 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 78, 'dropout_l0': 0.2753468632593256, 'optimizer': 'RMSprop', 'lr': 0.0019716096546593463}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:03,879]\u001b[0m Trial 50 finished with value: 0.81484375 and parameters: {'n_layers': 1, 'n_units_l0': 94, 'dropout_l0': 0.29327129517904926, 'optimizer': 'RMSprop', 'lr': 0.0024461772456163947}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:13,498]\u001b[0m Trial 51 finished with value: 0.809375 and parameters: {'n_layers': 1, 'n_units_l0': 93, 'dropout_l0': 0.2957515810340305, 'optimizer': 'RMSprop', 'lr': 0.0024329837566989592}. Best is trial 22 with value: 0.83125.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:14,279]\u001b[0m Trial 52 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:17,052]\u001b[0m Trial 53 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:17,777]\u001b[0m Trial 54 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:20,475]\u001b[0m Trial 55 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:27,722]\u001b[0m Trial 56 finished with value: 0.834375 and parameters: {'n_layers': 1, 'n_units_l0': 69, 'dropout_l0': 0.3343907932673326, 'optimizer': 'Adam', 'lr': 0.002319825585565234}. Best is trial 56 with value: 0.834375.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:28,524]\u001b[0m Trial 57 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:35,121]\u001b[0m Trial 58 finished with value: 0.84140625 and parameters: {'n_layers': 1, 'n_units_l0': 56, 'dropout_l0': 0.3640354622160226, 'optimizer': 'Adam', 'lr': 0.007167420981423627}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:37,828]\u001b[0m Trial 59 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:44,720]\u001b[0m Trial 60 finished with value: 0.82265625 and parameters: {'n_layers': 1, 'n_units_l0': 61, 'dropout_l0': 0.38037851664133404, 'optimizer': 'Adam', 'lr': 0.005771734892497874}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:45,441]\u001b[0m Trial 61 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:52,068]\u001b[0m Trial 62 finished with value: 0.81640625 and parameters: {'n_layers': 1, 'n_units_l0': 55, 'dropout_l0': 0.34115514250422957, 'optimizer': 'Adam', 'lr': 0.009245012806089095}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:52,818]\u001b[0m Trial 63 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:53:59,489]\u001b[0m Trial 64 finished with value: 0.784375 and parameters: {'n_layers': 1, 'n_units_l0': 49, 'dropout_l0': 0.35566523262234817, 'optimizer': 'Adam', 'lr': 0.011743256234972235}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:02,103]\u001b[0m Trial 65 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:02,848]\u001b[0m Trial 66 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:09,571]\u001b[0m Trial 67 finished with value: 0.8140625 and parameters: {'n_layers': 1, 'n_units_l0': 79, 'dropout_l0': 0.36979250341782327, 'optimizer': 'Adam', 'lr': 0.008174112133433524}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:16,200]\u001b[0m Trial 68 finished with value: 0.83359375 and parameters: {'n_layers': 1, 'n_units_l0': 71, 'dropout_l0': 0.3505683352965591, 'optimizer': 'Adam', 'lr': 0.0035457870436065362}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:22,965]\u001b[0m Trial 69 finished with value: 0.8328125 and parameters: {'n_layers': 1, 'n_units_l0': 71, 'dropout_l0': 0.3484127500518134, 'optimizer': 'Adam', 'lr': 0.003942940021809573}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:23,799]\u001b[0m Trial 70 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:30,664]\u001b[0m Trial 71 finished with value: 0.8390625 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.35316727836540895, 'optimizer': 'Adam', 'lr': 0.005585052671756463}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:32,061]\u001b[0m Trial 72 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:34,176]\u001b[0m Trial 73 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:41,482]\u001b[0m Trial 74 finished with value: 0.82421875 and parameters: {'n_layers': 1, 'n_units_l0': 63, 'dropout_l0': 0.330110248526623, 'optimizer': 'Adam', 'lr': 0.005734917834849563}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:42,197]\u001b[0m Trial 75 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:49,158]\u001b[0m Trial 76 finished with value: 0.80859375 and parameters: {'n_layers': 1, 'n_units_l0': 74, 'dropout_l0': 0.3249401446841772, 'optimizer': 'Adam', 'lr': 0.007115355314990007}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:50,031]\u001b[0m Trial 77 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:50,795]\u001b[0m Trial 78 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:51,544]\u001b[0m Trial 79 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:58,717]\u001b[0m Trial 80 finished with value: 0.8171875 and parameters: {'n_layers': 1, 'n_units_l0': 72, 'dropout_l0': 0.36941592429306047, 'optimizer': 'Adam', 'lr': 0.004508509774672968}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:54:59,489]\u001b[0m Trial 81 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:00,256]\u001b[0m Trial 82 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:07,723]\u001b[0m Trial 83 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:08,662]\u001b[0m Trial 84 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:09,780]\u001b[0m Trial 85 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:11,146]\u001b[0m Trial 86 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:22,319]\u001b[0m Trial 87 finished with value: 0.821875 and parameters: {'n_layers': 1, 'n_units_l0': 77, 'dropout_l0': 0.34446239634910236, 'optimizer': 'Adam', 'lr': 0.0029952563416367666}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:23,276]\u001b[0m Trial 88 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:34,005]\u001b[0m Trial 89 finished with value: 0.83125 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.34301768749798417, 'optimizer': 'Adam', 'lr': 0.005512416723529138}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:35,115]\u001b[0m Trial 90 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:45,412]\u001b[0m Trial 91 finished with value: 0.8125 and parameters: {'n_layers': 1, 'n_units_l0': 98, 'dropout_l0': 0.34690666241506357, 'optimizer': 'Adam', 'lr': 0.002979043074125719}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:55:56,068]\u001b[0m Trial 92 finished with value: 0.82578125 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.359526768618134, 'optimizer': 'Adam', 'lr': 0.005346202608180815}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:03,347]\u001b[0m Trial 93 finished with value: 0.8375 and parameters: {'n_layers': 1, 'n_units_l0': 92, 'dropout_l0': 0.3553080826754333, 'optimizer': 'Adam', 'lr': 0.008967041230108778}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:04,738]\u001b[0m Trial 94 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:11,772]\u001b[0m Trial 95 finished with value: 0.81796875 and parameters: {'n_layers': 1, 'n_units_l0': 85, 'dropout_l0': 0.33374585282492525, 'optimizer': 'Adam', 'lr': 0.009725114515393861}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:13,877]\u001b[0m Trial 96 pruned. \u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:20,723]\u001b[0m Trial 97 finished with value: 0.8203125 and parameters: {'n_layers': 1, 'n_units_l0': 81, 'dropout_l0': 0.3533694293758534, 'optimizer': 'Adam', 'lr': 0.003982104314656966}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:27,857]\u001b[0m Trial 98 finished with value: 0.83125 and parameters: {'n_layers': 1, 'n_units_l0': 97, 'dropout_l0': 0.3420211335555335, 'optimizer': 'Adam', 'lr': 0.0050541936586944655}. Best is trial 58 with value: 0.84140625.\u001b[0m\n",
      "\u001b[32m[I 2023-05-16 15:56:28,644]\u001b[0m Trial 99 pruned. \u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Study statistics: \n",
      "  Number of finished trials:  100\n",
      "  Number of pruned trials:  60\n",
      "  Number of complete trials:  40\n",
      "Best trial:\n",
      "  Value:  0.84140625\n",
      "  Params: \n",
      "    n_layers: 1\n",
      "    n_units_l0: 56\n",
      "    dropout_l0: 0.3640354622160226\n",
      "    optimizer: Adam\n",
      "    lr: 0.007167420981423627\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Optuna example that optimizes multi-layer perceptrons using PyTorch.\n",
    "\n",
    "In this example, we optimize the validation accuracy of fashion product recognition using\n",
    "PyTorch and FashionMNIST. We optimize the neural network architecture as well as the optimizer\n",
    "configuration. As it is too time consuming to use the whole FashionMNIST dataset,\n",
    "we here use a small subset of it.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "DEVICE = torch.device(\"cpu\")\n",
    "BATCHSIZE = 128\n",
    "CLASSES = 10\n",
    "DIR = os.getcwd()\n",
    "EPOCHS = 10\n",
    "N_TRAIN_EXAMPLES = BATCHSIZE * 30\n",
    "N_VALID_EXAMPLES = BATCHSIZE * 10\n",
    "\n",
    "\n",
    "def define_model(trial):\n",
    "    # We optimize the number of layers, hidden units and dropout ratio in each layer.\n",
    "    n_layers = trial.suggest_int(\"n_layers\", 1, 3)\n",
    "    layers = []\n",
    "\n",
    "    in_features = 28 * 28\n",
    "    for i in range(n_layers):\n",
    "        out_features = trial.suggest_int(\"n_units_l{}\".format(i), 4, 128)\n",
    "        layers.append(nn.Linear(in_features, out_features))\n",
    "        layers.append(nn.ReLU())\n",
    "        p = trial.suggest_float(\"dropout_l{}\".format(i), 0.2, 0.5)\n",
    "        layers.append(nn.Dropout(p))\n",
    "\n",
    "        in_features = out_features\n",
    "    layers.append(nn.Linear(in_features, CLASSES))\n",
    "    layers.append(nn.LogSoftmax(dim=1))\n",
    "\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def get_mnist():\n",
    "    # Load FashionMNIST dataset.\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=True, download=True, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        datasets.FashionMNIST(DIR, train=False, transform=transforms.ToTensor()),\n",
    "        batch_size=BATCHSIZE,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Generate the model.\n",
    "    model = define_model(trial).to(DEVICE)\n",
    "\n",
    "    # Generate the optimizers.\n",
    "    optimizer_name = trial.suggest_categorical(\"optimizer\", [\"Adam\", \"RMSprop\", \"SGD\"])\n",
    "    lr = trial.suggest_float(\"lr\", 1e-5, 1e-1, log=True)\n",
    "    optimizer = getattr(optim, optimizer_name)(model.parameters(), lr=lr)\n",
    "\n",
    "    # Get the FashionMNIST dataset.\n",
    "    train_loader, valid_loader = get_mnist()\n",
    "\n",
    "    # Training of the model.\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            # Limiting training data for faster epochs.\n",
    "            if batch_idx * BATCHSIZE >= N_TRAIN_EXAMPLES:\n",
    "                break\n",
    "\n",
    "            data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = F.nll_loss(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation of the model.\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, (data, target) in enumerate(valid_loader):\n",
    "                # Limiting validation data.\n",
    "                if batch_idx * BATCHSIZE >= N_VALID_EXAMPLES:\n",
    "                    break\n",
    "                data, target = data.view(data.size(0), -1).to(DEVICE), target.to(DEVICE)\n",
    "                output = model(data)\n",
    "                # Get the index of the max log-probability.\n",
    "                pred = output.argmax(dim=1, keepdim=True)\n",
    "                correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "        accuracy = correct / min(len(valid_loader.dataset), N_VALID_EXAMPLES)\n",
    "\n",
    "        trial.report(accuracy, epoch)\n",
    "\n",
    "        # Handle pruning based on the intermediate value.\n",
    "        if trial.should_prune():\n",
    "            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective, n_trials=100, timeout=600)\n",
    "\n",
    "    pruned_trials = study.get_trials(deepcopy=False, states=[TrialState.PRUNED])\n",
    "    complete_trials = study.get_trials(deepcopy=False, states=[TrialState.COMPLETE])\n",
    "\n",
    "    print(\"Study statistics: \")\n",
    "    print(\"  Number of finished trials: \", len(study.trials))\n",
    "    print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "    print(\"  Number of complete trials: \", len(complete_trials))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: \", trial.value)\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
